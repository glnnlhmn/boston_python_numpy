{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2554c25",
   "metadata": {},
   "source": [
    "# [Simple Linear Regression with examples using Numpy](https://medium.com/analytics-vidhya/simple-linear-regression-with-example-using-numpy-e7b984f0d15e)\n",
    "\n",
    "This topic was directly taken from an onlne article by [Arun Ramji Shanmugam](https://medium.com/@arunramji11)\n",
    "\n",
    "\n",
    "### What is Linear Regression ?\n",
    "\n",
    "Linear regression is the mathematical technique to guess the future outputs based on the past data.<br><br>\n",
    "For example, let’s say you are watching your favourite player playing football in today’s match, he is having very good track record against this opponent team with an average of 2 goals in every match, based on this simple calculation in your mind you may expect him to score at least 2 score or more than that, so what your brain did was calculating the simple average or mean.<br><br>\n",
    "**average = total score against opponent team / number of match against opponent**<br><br>\n",
    "Linear regression also similar to that but instead of taking an average, we are doing much better statistical guess using linear relationship between the input variable (x) and target variable (y).<br><br>\n",
    "Note: Linear Regression can be applied only for continuous variable like rain vs humidity , heart rate vs running speed etc .\n",
    "let’ see how to it works by implementing it in popular numerical computing python package NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb3c48",
   "metadata": {},
   "source": [
    "### Linear Regression using NumPy\n",
    "Step 1: Import all the necessary package will be used for computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea57b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277f1c3a",
   "metadata": {},
   "source": [
    "Step 2 : Read the input file using pandas library.  Take a quick peak at the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\glenn\\Downloads\\HappinessAlcoholConsumption.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ce6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Alcohol_PerCapita\"] = data[\"Beer_PerCapita\"] + data[\"Spirit_PerCapita\"] + data[\"Wine_PerCapita\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d425b4e4",
   "metadata": {},
   "source": [
    "Step 3: Filter only the required variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecfadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = data[['Alcohol_PerCapita', 'HappinessScore']]\n",
    "A.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2207f06",
   "metadata": {},
   "source": [
    "Step 4: Convert the pandas data frame in to numpy array ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array(A.values,'float')\n",
    "matrix[0:5,:]    #first 5 rows of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778164ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the Arrary\n",
    "print(\"matrix size: \", matrix.size)\n",
    "print(\"matrix shapre: \", matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b6715e",
   "metadata": {},
   "source": [
    "Step 5: Assign input and target variable, x and y for further computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044b776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign input and target variable\n",
    "X = matrix[:,0]\n",
    "y = matrix[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f03e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak at X and y\n",
    "X\n",
    "# y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438012a8",
   "metadata": {},
   "source": [
    "**Step 6:** Feature Normalisation <br>\n",
    "It is one of the important step for many ML models, what we actually do is compressing all our input variable in to smaller and similar magnitude so that later computation will be faster and efficient.<br><br>Below we have one of the feature normalisation technique to make the input variable x in similar magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78236125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature normalization\n",
    "# input variable divided by maximum value among input values in X\n",
    "X = X/(np.max(X)) \n",
    "\n",
    "# Normal distribution are figured between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523cbc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1894b",
   "metadata": {},
   "source": [
    "**Step 7:** Since it is one input variable and one output variable, we can plot the 2d plot and see how it is distributed. <br> This will help us to understand the data and problem in better way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# This will be covered in a leter study group today we are just going to use it\n",
    "\n",
    "plt.plot(X,y,'bo')\n",
    "plt.ylabel('Happiness Score')\n",
    "plt.xlabel('Alchohol consumption')\n",
    "plt.legend(['Happiness Score'])\n",
    "plt.title('Alchohol_Vs_Happiness')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc235a3",
   "metadata": {},
   "source": [
    "Now it is clear that there are some correlation between alcohol consumption and happiness score, which means we can see that country which consumes more alcohol tend to be more happy!!<br><br>\n",
    "\n",
    "**now let’s begin computing the hypothesis**\n",
    "<br><br>\n",
    "\n",
    ">Hypothesis testing is done to confirm our observation about the population using sample data, within the desired error level. Through hypothesis testing, we can determine whether we have enough statistical evidence to conclude if the hypothesis about the population is true or not.\n",
    "\n",
    "For a detailed explanation of hypothesis testing check out Brandon Foltz's  [Statistics 101 PL09 Hypothesis Testing](https://youtube.com/playlist?list=PLIeGtxpvyG-IZRHcZcOy12jp7ywuRbE7l) - Set aside an afternoon.\n",
    "\n",
    "---\n",
    "\n",
    "#### Create function to calulate SSE (Sum of Squared Error)\n",
    "\n",
    "> SSE is the difference between our hypothesis and actual data points\n",
    "\n",
    "**Step 8:** Define the function to calculate the cost or SSE.\n",
    "\n",
    "For a detailed explanation of [Sum of Squared Errors](https://youtu.be/6OvhLPS7rj4) check out Kahn Academy. (7 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computecost(x,y,theta):\n",
    "    \n",
    "    a = 1/(2*m)\n",
    "    b = np.sum(((x@theta)-y)**2)\n",
    "    j = (a)*(b)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbb55a7",
   "metadata": {},
   "source": [
    "**Step 9:** Appending a term x0 in our existing matrix X for mathematical convenience, x0 should be having values as ‘1’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81896d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising parameter\n",
    "m = np.size(y)\n",
    "X = X.reshape([122,1])\n",
    "# np.hstack concatenates arrays column-wise\n",
    "x = np.hstack([np.ones_like(X),X])\n",
    "theta = np.zeros([2,1])\n",
    "print(theta,'\\n',m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca4457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(computecost(x,y,theta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94106472",
   "metadata": {},
   "source": [
    "Gradient descend is a one such algorithm used to find the optimal parameter ‘theta’ using the given parameters, <br><br>\n",
    "x — Input values<br>\n",
    "y — output values<br>\n",
    "Initial_theta — in most cases NULL theta<br>\n",
    "alpha — rate at which gradient pointer descending to optimal value<br>\n",
    "iteration — setting how many iteration it should take <br><br>\n",
    "understanding [“Gradinet Desecnd”](https://youtu.be/sDv4f4s2SB8) may require bit of calculus , but it is not necessary to implement and using it for ML problems . Knowing the role of the above mentioned parameters is often enough for implementation.\n",
    "\n",
    "---\n",
    "**Step 10:** Defining function for gradient descent algorithm .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb3dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x,y,theta):\n",
    "    \n",
    "    alpha = 0.00001\n",
    "    iteration = 2000\n",
    "    \n",
    "    #gradient descend algorithm\n",
    "    J_history = np.zeros([iteration, 1])\n",
    "    \n",
    "    for iter in range(0,2000):\n",
    "        \n",
    "        error = (x @ theta) -y\n",
    "        temp0 = theta[0] - ((alpha/m) * np.sum(error*x[:,0]))\n",
    "        temp1 = theta[1] - ((alpha/m) * np.sum(error*x[:,1]))\n",
    "        theta = np.array([temp0,temp1]).reshape(2,1)\n",
    "        J_history[iter] = (1 / (2*m) ) * (np.sum(((x @ theta)-y)**2))   #compute J value for each iteration \n",
    " \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d483cc7",
   "metadata": {},
   "source": [
    "Now let’s use the gradient function for our data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ae732",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta , J = gradient(x,y,theta)\n",
    "print('theta:')\n",
    "print(theta)\n",
    "print('J:')\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2e16c",
   "metadata": {},
   "source": [
    "cost or SSE value is 115.42 which is much better than 1941.78 was calculated when theta = 0<br>\n",
    "\n",
    "---\n",
    "**Step 11:** Now let’s plot our line on data to see how well it fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84caeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot linear fit for our theta\n",
    "plt.plot(X,y,'bo')\n",
    "plt.plot(X,x@theta,'-')\n",
    "plt.axis([0,1,3,7])\n",
    "plt.ylabel('Happiness Score')\n",
    "plt.xlabel('Alcohol consumption')\n",
    "plt.legend(['HAPPY','LinearFit'])\n",
    "plt.title('Alcohol_Vs_Happiness')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec758f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
